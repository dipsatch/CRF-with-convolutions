{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "from data_loader import get_dataset\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset()\n",
    "split = int(0.5 * len(dataset.data)) # train-test split\n",
    "train_data, test_data = dataset.data[:split], dataset.data[split:]\n",
    "train_target, test_target = dataset.target[:split], dataset.target[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=torch.from_numpy(train_data).float()\n",
    "train_Y=torch.from_numpy(train_target).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.txt') as f:\n",
    "    content=f.readlines()\n",
    "x=[float(x.rstrip()) for x in content]\n",
    "num_features = 128 #128\n",
    "num_label = int((math.sqrt(num_features**2+4*len(x)) - num_features)/2) #26\n",
    "W = np.reshape(x[:num_features*num_label], (num_features, num_label), order='F')\n",
    "T = np.reshape(x[num_features*num_label:], (num_label, num_label), order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#considering W and T of assignment 2\n",
    "W=torch.from_numpy(W)\n",
    "T=torch.from_numpy(T)\n",
    "x=torch.from_numpy(np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Messages(x, X, y,W,T):    \n",
    "    num_ex=len(X)\n",
    "    w=X[0]\n",
    "    num_features = len(w[1]) #128\n",
    "    num_label = int((math.sqrt(num_features**2+4*len(x)) - num_features)/2) #26\n",
    "    \n",
    "    l = torch.zeros((num_ex,num_label, 100)).double()\n",
    "    r = torch.zeros((num_ex,num_label, 100)).double()\n",
    "    \n",
    "\n",
    "    for ex in range(num_ex):\n",
    "        word_label = torch.nonzero(y[ex])[:,1].numpy()\n",
    "        word = X[ex,:len(word_label)]      \n",
    "        num_letter = len(word_label)             \n",
    "\n",
    "        def letter_func(l):\n",
    "#             print(W)\n",
    "#             print(np.matmul(l,W))\n",
    "            return l.matmul(W)        \n",
    "        \n",
    "        score=torch.stack([letter_func(l.double()) for i,l in enumerate(torch.unbind(word,dim=0),0)],dim=1)\n",
    "\n",
    "\n",
    "        l[ex,:,0] = 0\n",
    "        r[ex,:,num_letter-1] = 0\n",
    "        for i in range(1, num_letter):\n",
    "            v=l[ex,:,i-1].add(score[:,i-1]).view(num_label,1)\n",
    "            temp = T.add(v.repeat(1,num_label))\n",
    "            max_temp = torch.max(temp, dim=0)[0].view((1,num_label))\n",
    "            l[ex,:, i] = torch.add(torch.log(torch.sum(torch.exp((temp-max_temp.repeat(num_label,1)).double()), dim=0)), max_temp)\n",
    "\n",
    "        for i in range(num_letter-2, -1, -1):\n",
    "            v = r[ex,:,i+1].add(score[:,i+1]).view(num_label,1)\n",
    "            temp = T.add(v.t().repeat(num_label,1))\n",
    "            max_temp = torch.max(temp, dim=1)[0].view(num_label,1)\n",
    "            r[ex,:, i] = torch.add(torch.log(torch.sum(torch.exp((temp-max_temp.repeat(1,num_label)).double()), dim=1).view(26,1)), max_temp).t()\n",
    "    return l,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(logprob,x,C,N):\n",
    "    if C>0:\n",
    "        obj = torch.norm(x.float())**2/2 - logprob*C/N\n",
    "    else: \n",
    "        \n",
    "        obj = logprob / N\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_probability(X,y,l,r,T,W):\n",
    "    num_ex=len(X)\n",
    "    f = 0\n",
    "    for ex in range(num_ex):\n",
    "        word_label = torch.nonzero(y[ex])[:,1].numpy()\n",
    "        word = X[ex,:len(word_label)]      \n",
    "        num_letter = len(word_label)\n",
    "        \n",
    "        def letter_func(l):\n",
    "            return l.matmul(W)        \n",
    "        \n",
    "        score=torch.stack([letter_func(l.double()) for i,l in enumerate(torch.unbind(word,dim=0),0)],dim=1)\n",
    "        \n",
    "        l_plus_score = torch.add(l[ex,:, :num_letter], score)\n",
    "        r_plus_score = torch.add(r[ex,:, :num_letter], score)     \n",
    "        marg = torch.add(l_plus_score, r_plus_score)\n",
    "        marg = marg-score\n",
    "        t = torch.max(marg[:,0])\n",
    "        f = f - math.log(torch.sum(torch.exp((marg[:,0]-t).float()))) - t\n",
    "        for i in range(num_letter):\n",
    "                lab = word_label[i]\n",
    "                f = f + score[lab][i]\n",
    "                if i < num_letter-1:\n",
    "                    next_lab = word_label[i+1]\n",
    "                    f = f + T[lab][next_lab]\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeGrad(X,y,T,l,r):\n",
    "    num_ex=len(X)\n",
    "    g_W = torch.zeros(W.shape)\n",
    "    g_T = torch.zeros(T.shape)\n",
    "    for ex in range(num_ex):\n",
    "        word_label = torch.nonzero(y[ex])[:,1].numpy()\n",
    "        word = X[ex,:len(word_label)]\n",
    "        num_letter = len(word_label)\n",
    "        \n",
    "        \n",
    "        def letter_func(l):\n",
    "#             print(np.matmul(l,W))\n",
    "            return l.matmul(W) \n",
    "        \n",
    "        #exp(<w.x>) \n",
    "        score=torch.stack([letter_func(l.double()) for i,l in enumerate(torch.unbind(word,dim=0),0)],dim=1)\n",
    "        \n",
    "        \n",
    "        l_plus_score = torch.add(l[ex,:, :num_letter], score)\n",
    "        r_plus_score = torch.add(r[ex,:, :num_letter], score)     \n",
    "        marg = torch.add(l_plus_score, r_plus_score)\n",
    "        marg = marg-score # because score is added twice\n",
    "        marg = torch.exp((marg-torch.max(marg, dim=0)[0].repeat(num_label, 1)).float())\n",
    "        marg = marg/torch.sum(marg, dim=0).repeat(num_label, 1) # Normalization \n",
    "        \n",
    "        for i in range(num_letter):\n",
    "            lab = word_label[i]\n",
    "            V = marg[:,i].view(num_label,1)\n",
    "            V[lab] = V[lab] - 1\n",
    "            g_W = g_W-torch.matmul(word[i].view(num_features,1), V.t())\n",
    "            if i < num_letter-1:\n",
    "                next_lab = word_label[i+1]\n",
    "                V = torch.add(T, l_plus_score[:,i].view(num_label,1).repeat(1, num_label))\n",
    "                V = torch.add(V, r_plus_score[:,i+1].view(num_label,1).t().repeat(num_label, 1))\n",
    "                V = torch.exp((V - torch.max(V)).float())\n",
    "                g_T = g_T - V / torch.sum(V)\n",
    "                g_T[lab][next_lab] = g_T[lab][next_lab] + 1\n",
    "    grad=torch.cat((g_W.view(-1), g_T.view(-1)))\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-102439.6996, dtype=torch.float64)\n",
      "8.509279727935791\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "s=time.time()\n",
    "f,b=Messages(x,train_X,train_Y,W,T)\n",
    "logp=compute_log_probability(train_X,train_Y,f,b,T,W)\n",
    "print(logp)\n",
    "g=ComputeGrad(train_X,train_Y,T,f,b)\n",
    "print(time.time()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-29.7963, dtype=torch.float64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.from_numpy(np.array(x))\n",
    "loss(logp,x,-1,len(train_X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
